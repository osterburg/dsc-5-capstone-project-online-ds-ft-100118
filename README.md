[<center><img src='images/newsstand.jpg'></center>](https://github.com/osterburg/dsc-5-capstone-project-online-ds-ft-100118/FakeNews/assets/player/KeynoteDHTMLPlayer.html)

# Capstone Project - News Content

Over the past two decades and especially since the United States presidential election 2016 there is an increase in unreliable news content. The question which got and still gets asked is how can we know which is which. To find an answer I started at [opensources](http://www.opensources.co/) which curates a list of online information sources. The websites listed range from credible news to misleading and outright fake.

I split the project into three different notebooks:

+ collecting content
+ data exploration
+ creating a keras model

I am interested in trying to answer the following questions:

+ how much unreliable content can we find
+ what makes that content different
+ can we create deep learning models to help us differentiate

What are the next steps?

+ create a dashboard to copy/paste news content to make a prediction
+ add classifiers to distinguish the text better based on its "content" and "context".
